{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1293252162701725695\n",
      "...386 tweets downloaded so far\n",
      "getting tweets before 292903444233207809\n",
      "...581 tweets downloaded so far\n",
      "getting tweets before 265207522573574143\n",
      "...769 tweets downloaded so far\n",
      "getting tweets before 223566772656291840\n",
      "...948 tweets downloaded so far\n",
      "getting tweets before 200244538093207551\n",
      "...1140 tweets downloaded so far\n",
      "getting tweets before 179842668396945407\n",
      "...1170 tweets downloaded so far\n",
      "getting tweets before 128727410161102847\n",
      "...1170 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = \"*********\"\n",
    "consumer_secret = \"*****\"\n",
    "access_key = \"****\"\n",
    "access_secret = \"******\"\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []  \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = \"type username\",count=200)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(f\"getting tweets before {oldest}\")\n",
    "        \n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "    \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv \n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text] for tweet in alltweets]\n",
    "    \n",
    "    #write the csv  \n",
    "    with open(f'new_{screen_name}_tweets.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "        writer.writerows(outtweets)\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t#pass in the username of the account you want to download\n",
    "\tget_all_tweets(\"downloaded file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
